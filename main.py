import pymysql
import requests
import os
import time
from bs4 import BeautifulSoup
from fastapi import FastAPI, Request
from fastapi.templating import Jinja2Templates
from dotenv import load_dotenv
import google.generativeai as genai

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
DB_PASSWORD = os.getenv('DB_PASSWORD')

# 2. AI ì„¤ì • (ì¤‘ìš”: ëª¨ë¸ëª… ìˆ˜ì •ë¨ gemini-1.5-flash)
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

app = FastAPI()
templates = Jinja2Templates(directory="templates")

# 3. DB ì„¤ì •
DB_CONFIG = {
    'host': 'bitnmeta2.synology.me',
    'user': 'iyrc',
    'passwd': DB_PASSWORD,
    'db': 'gemini_ai',
    'charset': 'utf8',
    'port': 3307,
    'cursorclass': pymysql.cursors.DictCursor
}

# ë¶„ì„ ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…
TREND_FILE = "latest_trend.txt"

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 1] DB ë„ìš°ë¯¸ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------
def is_link_exist(link):
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT id FROM ai_news WHERE link=%s", (link,))
        return cursor.fetchone() is not None
    except:
        return False
    finally:
        if conn: conn.close()

def save_news(title, link, summary):
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        sql = "INSERT IGNORE INTO ai_news (title, link, summary, created_at) VALUES (%s, %s, %s, NOW())"
        cursor.execute(sql, (title, link, summary))
        conn.commit()
    except Exception as e:
        print(f"DB Error: {e}")
    finally:
        if conn: conn.close()

def send_telegram_message(text):
    # ì•„ì§ ë¯¸ì²˜ë¦¬ ë˜ì—ˆìŒ TELEGRAM_TOKEN ì´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
    if not TELEGRAM_TOKEN:
        return
    try:
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage", 
            data={"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "HTML"}
        )
    except:
        pass

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 2] AI ìš”ì•½ ë° ë¶„ì„ í•¨ìˆ˜
# ---------------------------------------------------------
def summarize_news_with_ai(title, content):
    try:
        prompt = f"""
        ë„ˆëŠ” IT ë‰´ìŠ¤ ì „ë¬¸ ë¶„ì„ê°€ì•¼. ì•„ë˜ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ìš”ì•½í•´ì¤˜.
        
        [ê·œì¹™]
        1. ë³¸ë¬¸ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë©´ 'ì œëª©'ì„ ë³´ê³  ë‚´ìš©ì„ ì¶”ë¡ í•´ì„œ ì‘ì„±í•  ê²ƒ.
        2. '- ' ê¸€ë¨¸ë¦¬ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•´ 5~7ì¤„ ë‚´ì™¸ë¡œ ì‘ì„±.
        
        [ì œëª©]: {title}
        [ë‚´ìš©]: {content}
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"âš ï¸ ê°œë³„ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return "ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_trend_analysis(news_data_list):
    try:
        combined_titles = "\n".join([f"- {news['title']}" for news in news_data_list])
        prompt = f"""
        ì•„ë˜ëŠ” ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ì£¼ìš” AI ê´€ë ¨ ë‰´ìŠ¤ 10ê°œì˜ ì œëª©ë“¤ì´ë‹¤.
        ì´ ë‰´ìŠ¤ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ 'ì˜¤ëŠ˜ì˜ AI ì‚°ì—… ë™í–¥'ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì¤˜.
        
        [ì‘ì„± ê·œì¹™]
        1. ì „ì²´ì ì¸ íŠ¸ë Œë“œë‚˜ ê³µí†µëœ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ì„œ ì„¤ëª…í•  ê²ƒ.
        2. 'ì˜¤ëŠ˜ì˜ í•µì‹¬ í‚¤ì›Œë“œ: OOO, OOO' í˜•ì‹ì„ í¬í•¨í•  ê²ƒ.
        3. ì„œìˆ í˜•ìœ¼ë¡œ 5ì¤„ ë‚´ì™¸ë¡œ ìš”ì•½í•  ê²ƒ.
        
        [ë‰´ìŠ¤ ëª©ë¡]:
        {combined_titles}
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"âš ï¸ ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {e}")
        return "ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 3] ë©”ì¸ ë¡œì§ (ìŠ¤í¬ë˜í•‘ -> ìš”ì•½ -> DB -> í…”ë ˆê·¸ë¨ -> ì¢…í•©ë¶„ì„)
# ---------------------------------------------------------
def scrape_and_process():
    url = "https://news.google.com/rss/search?q=AI+ì¸ê³µì§€ëŠ¥&hl=ko&gl=KR&ceid=KR:ko"
    
    try:
        print("ğŸš€ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
        response = requests.get(url)
        soup = BeautifulSoup(response.content, features="xml")
        items = soup.findAll('item')
        
        processed_list = []
        new_count = 0
        
        # 10ê°œ ì²˜ë¦¬
        for item in items[:10]:
            title = item.title.text
            link = item.link.text
            raw_desc = item.description.text if item.description else ""
            
            # íƒœê·¸ ì œê±°
            soup_desc = BeautifulSoup(raw_desc, "html.parser")
            cleaned_text = soup_desc.get_text(separator=" ", strip=True)
            
            # ì¤‘ë³µ ì²´í¬
            if is_link_exist(link):
                print(f"PASS: {title[:10]}...")
                processed_list.append({'title': title}) 
                continue

            # AI ìš”ì•½
            context = cleaned_text if len(cleaned_text) > 10 else f"ë³¸ë¬¸ ë‚´ìš© ì—†ìŒ. ì œëª©({title}) ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ í•„ìš”."
            summary = summarize_news_with_ai(title, context)
            
            # DB ì €ì¥ ë° í…”ë ˆê·¸ë¨ ì „ì†¡
            save_news(title, link, summary)
            new_count += 1
            processed_list.append({'title': title})
            
            msg = f"<b>ğŸ“° {title}</b>\n\n{summary}\n\nğŸ”— <a href='{link}'>ì›ë¬¸ ë³´ê¸°</a>"
            send_telegram_message(msg)
            
            print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {title[:10]}...")
            time.sleep(1)

        # ì¢…í•© ë¶„ì„
        if processed_list:
            print("ğŸ“Š ì¢…í•© íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
            trend_report = generate_trend_analysis(processed_list)
            with open(TREND_FILE, "w", encoding="utf-8") as f:
                f.write(trend_report)
                
        return new_count
        
    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì—ëŸ¬: {e}")
        return 0

# ---------------------------------------------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ---------------------------------------------------------
@app.get("/")
def read_root(request: Request):
    conn = None
    news_list = []
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM ai_news ORDER BY id DESC LIMIT 10")
        news_list = cursor.fetchall()
    except Exception as e:
        print(f"DB Read Error: {e}")
    finally:
        if conn: conn.close()
    
    trend_report = "ì•„ì§ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
    if os.path.exists(TREND_FILE):
        with open(TREND_FILE, "r", encoding="utf-8") as f:
            trend_report = f.read()

    return templates.TemplateResponse("index.html", {
        "request": request, 
        "news_list": news_list,
        "trend_report": trend_report
    })

@app.get("/scrape")
def trigger_scrape():
    print("ğŸ”” /scrape ìš”ì²­ ë°›ìŒ")
    count = scrape_and_process()
    return {"status": "success", "message": f"{count}ê±´ ì‹ ê·œ ìˆ˜ì§‘ ë° ì¢…í•© ë¶„ì„ ì™„ë£Œ!"}