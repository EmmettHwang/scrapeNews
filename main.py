import pymysql
import requests
import os
import time
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai
from fastapi import FastAPI, Request, Form
from fastapi.responses import RedirectResponse
from fastapi.templating import Jinja2Templates

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID') # ê´€ë¦¬ì í…ŒìŠ¤íŠ¸ìš©
DB_PASSWORD = os.getenv('DB_PASSWORD')

# 2. AI ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

app = FastAPI()
templates = Jinja2Templates(directory="templates")

# 3. DB ì„¤ì •
DB_CONFIG = {
    'host': 'bitnmeta2.synology.me',
    'user': 'iyrc',
    'passwd': DB_PASSWORD,
    'db': 'gemini_ai',
    'charset': 'utf8',
    'port': 3307,
    'cursorclass': pymysql.cursors.DictCursor
}

# ë¶„ì„ ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…
TREND_FILE = "latest_trend.txt"

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 1] DB ë° í…”ë ˆê·¸ë¨ ë„ìš°ë¯¸ í•¨ìˆ˜ë“¤
# ---------------------------------------------------------
def is_link_exist(link):
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT id FROM ai_news WHERE link=%s", (link,))
        return cursor.fetchone() is not None
    except:
        return False
    finally:
        if conn: conn.close()

def save_news(title, link, summary):
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        sql = "INSERT IGNORE INTO ai_news (title, link, summary, created_at) VALUES (%s, %s, %s, NOW())"
        cursor.execute(sql, (title, link, summary))
        conn.commit()
    except Exception as e:
        print(f"DB Error: {e}")
    finally:
        if conn: conn.close()

# (ë‹¨ì¼ ë°œì†¡ìš© - ê´€ë¦¬ì í…ŒìŠ¤íŠ¸ ë“±)
def send_telegram_message(text):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("âš ï¸ í…”ë ˆê·¸ë¨ ì„¤ì •(í† í°/ID)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID, 
        "text": text, 
        "parse_mode": "HTML"
    }

    try:
        response = requests.post(url, data=payload, timeout=10)
        if response.status_code != 200:
            print(f"âŒ í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {response.text}")
    except Exception as e:
        print(f"âŒ í…”ë ˆê·¸ë¨ ì—°ê²° ì—ëŸ¬: {e}")

# (êµ¬ë…ì ì „ì²´ ë°œì†¡ìš©)
def send_telegram_to_all(text):
    if not TELEGRAM_TOKEN:
        print("âš ï¸ í…”ë ˆê·¸ë¨ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    conn = None
    try:
        # 1. êµ¬ë…ì ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT nickname, chat_id FROM subscribers")
        subscribers = cursor.fetchall()
        
        if not subscribers:
            print("âš ï¸ ë°œì†¡í•  êµ¬ë…ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"

        # 2. í•œ ëª…ì”© ìˆœì„œëŒ€ë¡œ ì „ì†¡
        print(f"ğŸ“¨ ì´ {len(subscribers)}ëª…ì—ê²Œ ë°œì†¡ ì‹œì‘...")
        
        for sub in subscribers:
            chat_id = sub['chat_id']
            payload = {"chat_id": chat_id, "text": text, "parse_mode": "HTML"}
            
            try:
                resp = requests.post(url, data=payload, timeout=5)
                if resp.status_code == 200:
                    print(f" - {sub['nickname']}ë‹˜ ì „ì†¡ ì„±ê³µ")
                else:
                    print(f" - {sub['nickname']}ë‹˜ ì „ì†¡ ì‹¤íŒ¨: {resp.text}")
            except Exception as e:
                print(f" - ì „ì†¡ ì—ëŸ¬ ({sub['nickname']}): {e}")
            
            # ë„ˆë¬´ ë¹¨ë¦¬ ë³´ë‚´ë©´ í…”ë ˆê·¸ë¨ì´ ì°¨ë‹¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•½ê°„ ëŒ€ê¸°
            time.sleep(0.5)

    except Exception as e:
        print(f"DB ì ‘ì† ì—ëŸ¬: {e}")
    finally:
        if conn: conn.close()

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 2] AI ìš”ì•½ ë° ë¶„ì„ í•¨ìˆ˜
# ---------------------------------------------------------
def summarize_news_with_ai(title, content):
    try:
        # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œëª©ì„ ë‚´ìš©ìœ¼ë¡œ ì‚¬ìš©
        if len(content) < 20:
            actual_content = f"ì œëª©: {title}"
        else:
            actual_content = content

        prompt = f"""
        ë„ˆëŠ” IT ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ë´‡ì´ì•¼. ì•„ë˜ ë‰´ìŠ¤ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ 2~3ì¤„ ìš”ì•½ì„ ì‘ì„±í•´.
        
        [ì§€ì¹¨]
        1. 'ë‚´ìš©'ì´ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆë‹¤ë©´, 'ì œëª©'ë§Œ ë³´ê³  ì–´ë–¤ ë‰´ìŠ¤ì¸ì§€ ì¶”ë¡ í•´ì„œ ì‘ì„±í•´.
        2. ì ˆëŒ€ 'ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§í•˜ì§€ ë§ˆ.
        3. ë¬¸ì¥ì€ "~í•¨", "~ì„", "~ê²ƒìœ¼ë¡œ ë³´ì„" ê°™ì€ ëª…ì‚¬í˜• ì–´ë¯¸ë¡œ ëë‚´.
        
        [ì œëª©]: {title}
        [ë‚´ìš©]: {actual_content}
        """
        
        # ì•ˆì „ ì„¤ì • (í•„í„°ë§ ê¸°ì¤€ì„ ë‚®ì¶°ì„œ ë‰´ìŠ¤ê°€ ì°¨ë‹¨ë˜ì§€ ì•Šê²Œ í•¨)
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        response = model.generate_content(prompt, safety_settings=safety_settings)
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        if response.text:
            return response.text
        else:
            return f"{title} (ìƒì„¸ ë‚´ìš© í™•ì¸ í•„ìš”)"

    except Exception as e:
        print(f"âš ï¸ AI í˜¸ì¶œ ì—ëŸ¬: {e}")
        # AIê°€ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ì œëª©ì´ë¼ë„ ê¹”ë”í•˜ê²Œ ë°˜í™˜ (ë¶„ì„ ë¶ˆê°€ ë©”ì‹œì§€ ì œê±°)
        return f"ì£¼ìš” ë‰´ìŠ¤: {title}"

def generate_trend_analysis(news_data_list):
    try:
        # ë‰´ìŠ¤ ì œëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±
        combined_titles = "\n".join([f"- {news['title']}" for news in news_data_list])
        
        prompt = f"""
        ì•„ë˜ëŠ” í˜„ì¬ ìˆ˜ì§‘ëœ ì£¼ìš” AI ê´€ë ¨ ë‰´ìŠ¤ ì œëª©ë“¤ì´ë‹¤. (ì´ {len(news_data_list)}ê±´)
        ì´ ë‰´ìŠ¤ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ 'AI ì‚°ì—… ë‰´ìŠ¤ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì¤˜. 
        ë‰´ìŠ¤ê°€ 10ê°œ ë¯¸ë§Œì´ì–´ë„ ìˆëŠ” ì •ë³´ë§Œìœ¼ë¡œ ë¶„ì„í•´ë¼.

        [ì‘ì„± ê·œì¹™]
        1. í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ë¡œ ë³´ë‚¼ ê²ƒì´ë¯€ë¡œ ê°€ë…ì„± ì¢‹ê²Œ ì‘ì„±í•  ê²ƒ.
        2. HTML íƒœê·¸ <b> (ë³¼ë“œì²´)ë§Œ ì‚¬ìš© ê°€ëŠ¥ (ë§ˆí¬ë‹¤ìš´ ** ì‚¬ìš© ê¸ˆì§€).
        3. ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¥¼ ê²ƒ:

        <b>[ğŸ“… ì˜¤ëŠ˜ì˜ AI ë‰´ìŠ¤ ë¸Œë¦¬í•‘]</b>
        
        <b>1. í•µì‹¬ í‚¤ì›Œë“œ</b>
        : (í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ)

        <b>2. ì£¼ìš” ë™í–¥ ìš”ì•½</b>
        : (ì „ì²´ì ì¸ íë¦„ì„ 3~5ì¤„ë¡œ ìš”ì•½)

        <b>3. ì£¼ìš” í—¤ë“œë¼ì¸</b>
        : (ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ ì œëª© 3ê°œë§Œ ë‚˜ì—´)

        [ë‰´ìŠ¤ ëª©ë¡]:
        {combined_titles}
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"âš ï¸ ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {e}")
        return "ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

# ---------------------------------------------------------
# [ê¸°ëŠ¥ 3] ë©”ì¸ ë¡œì§ (ìŠ¤í¬ë˜í•‘ -> ìš”ì•½ -> DB -> ì¢…í•©ë¶„ì„ -> êµ¬ë…ì ì „ì› ì „ì†¡)
# ---------------------------------------------------------
def scrape_and_process():
    url = "https://news.google.com/rss/search?q=AI+ì¸ê³µì§€ëŠ¥&hl=ko&gl=KR&ceid=KR:ko"
    
    try:
        print("ğŸš€ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
        response = requests.get(url)
        soup = BeautifulSoup(response.content, features="xml")
        items = soup.findAll('item')
        
        processed_list = []
        new_count = 0
        
        target_items = items[:10]
        
        for item in target_items:
            title = item.title.text
            link = item.link.text
            
            # description ì²˜ë¦¬ ê°•í™”
            raw_desc = item.description.text if item.description else ""
            soup_desc = BeautifulSoup(raw_desc, "html.parser")
            cleaned_text = soup_desc.get_text(separator=" ", strip=True)
            
            # [í•µì‹¬ ìˆ˜ì •] ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œëª©ì„ ë‚´ìš©ìœ¼ë¡œ ê°„ì£¼ (êµ¬ê¸€ ë‰´ìŠ¤ëŠ” ë³¸ë¬¸ì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŒ)
            if len(cleaned_text) < 10:
                context = f"ê¸°ì‚¬ ì œëª©: {title}. (ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°ê°€ ì œê³µë˜ì§€ ì•ŠëŠ” ê¸°ì‚¬ì…ë‹ˆë‹¤.)"
            else:
                context = cleaned_text

            processed_list.append({'title': title}) 

            if is_link_exist(link):
                print(f"PASS (ì¤‘ë³µ): {title[:10]}...")
                continue 

            # ìš”ì•½ í•¨ìˆ˜ í˜¸ì¶œ
            summary = summarize_news_with_ai(title, context)
            
            save_news(title, link, summary)
            new_count += 1
            
            print(f"âœ… DB ì €ì¥ ì™„ë£Œ: {title[:10]}...")
            time.sleep(1)

        if processed_list:
            print(f"ğŸ“Š ì´ {len(processed_list)}ê±´ì˜ ë‰´ìŠ¤ë¡œ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
            trend_report = generate_trend_analysis(processed_list)
            
            with open(TREND_FILE, "w", encoding="utf-8") as f:
                f.write(trend_report)
            
            send_telegram_to_all(trend_report)
            print("ğŸ“¨ í…”ë ˆê·¸ë¨ ì¢…í•© ë¸Œë¦¬í•‘ ì „ì†¡ ì™„ë£Œ")
        else:
            print("âš ï¸ ì²˜ë¦¬í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        return new_count        
    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì—ëŸ¬: {e}")
        return 0
# ---------------------------------------------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ---------------------------------------------------------
@app.get("/")
def read_root(request: Request):
    conn = None
    news_list = []
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM ai_news ORDER BY id DESC LIMIT 10")
        news_list = cursor.fetchall()
    except Exception as e:
        print(f"DB Read Error: {e}")
    finally:
        if conn: conn.close()
    
    trend_report = "ì•„ì§ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
    if os.path.exists(TREND_FILE):
        with open(TREND_FILE, "r", encoding="utf-8") as f:
            trend_report = f.read()
    
    return templates.TemplateResponse("index.html", {
        "request": request, 
        "news_list": news_list,
        "trend_report": trend_report
    })

@app.get("/scrape")
def trigger_scrape():
    print("ğŸ”” /scrape ìš”ì²­ ë°›ìŒ")
    count = scrape_and_process()
    return {"status": "success", "message": f"{count}ê±´ ì‹ ê·œ ìˆ˜ì§‘ ë° êµ¬ë…ì ë°œì†¡ ì™„ë£Œ!"}

# ---------------------------------------------------------
# [ê¸°ëŠ¥ ì¶”ê°€] êµ¬ë… ì‹ ì²­ API
# ---------------------------------------------------------
@app.post("/subscribe")
def subscribe_user(nickname: str = Form(...), chat_id: str = Form(...)):
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # ì¤‘ë³µ ë°©ì§€ (ì´ë¯¸ ë“±ë¡ëœ Chat IDë©´ ë¬´ì‹œ)
        # DBì— subscribers í…Œì´ë¸”ì´ ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•¨
        sql = "INSERT IGNORE INTO subscribers (nickname, chat_id) VALUES (%s, %s)"
        cursor.execute(sql, (nickname, chat_id))
        conn.commit()
        
        print(f"ğŸ”” ì‹ ê·œ êµ¬ë…ì ë“±ë¡: {nickname} ({chat_id})")
    except Exception as e:
        print(f"êµ¬ë… ì—ëŸ¬: {e}")
    finally:
        if conn: conn.close()
    
    # ë“±ë¡ í›„ ë‹¤ì‹œ ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™
    return RedirectResponse(url="/", status_code=303)